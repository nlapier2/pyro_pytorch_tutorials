{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scANVI Pyro Tutorial\n",
    "\n",
    "This notebook follows the Pyro tutorial on implementing a bare-bones version of the scANVI model: https://pyro.ai/examples/scanvi.html\n",
    "\n",
    "scANVI (https://doi.org/10.15252/msb.20209620) is a method based on conditional variational autoencoders (CVAEs) that learns cell state representations from single-cell RNA-seq data. It is a semi-supervised method that uses cell type labels when available. In this notebook, we will approximately reproduce Figure 6 in the scANVI paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and data preprocessing\n",
    "\n",
    "We use the scvi-tools package to download some PBMC scRNA-seq data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup environment\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)  # for continuous integration tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# various import statements\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import softplus, softmax\n",
    "from torch.distributions import constraints\n",
    "from torch.optim import Adam\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from pyro.distributions.util import broadcast_shape\n",
    "from pyro.optim import MultiStepLR\n",
    "from pyro.infer import SVI, config_enumerate, TraceEnum_ELBO\n",
    "from pyro.contrib.examples.scanvi_data import get_data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m File data/PurifiedPBMCDataset.h5ad already downloaded                                                     \n"
     ]
    }
   ],
   "source": [
    "# Download and pre-process data\n",
    "batch_size = 100\n",
    "if not smoke_test:\n",
    "    # dataloader, num_genes, l_mean, l_scale, anndata = get_data(dataset='pbmc', cuda=True, batch_size=batch_size)\n",
    "    dataloader, num_genes, l_mean, l_scale, anndata = get_data(dataset='pbmc', cuda=False, batch_size=batch_size)\n",
    "else:\n",
    "    dataloader, num_genes, l_mean, l_scale, anndata = get_data(dataset='mock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count data matrix shape: torch.Size([20000, 21932])\n",
      "Mean counts per cell: 1418.6\n",
      "Number of labeled cells: 200\n"
     ]
    }
   ],
   "source": [
    "# get some basic info about the data\n",
    "print(\"Count data matrix shape:\", dataloader.data_x.shape)\n",
    "print(\"Mean counts per cell: {:.1f}\".format(dataloader.data_x.sum(-1).mean().item()))\n",
    "print(\"Number of labeled cells:\", dataloader.num_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some helper functions for reshaping tensors and \n",
    "#   making fully-connected neural networks (see scANVI paper to see where these are used)\n",
    "\n",
    "# Helper for making fully-connected neural networks\n",
    "def make_fc(dims):\n",
    "    layers = []\n",
    "    for in_dim, out_dim in zip(dims, dims[1:]):\n",
    "        layers.append(nn.Linear(in_dim, out_dim))\n",
    "        layers.append(nn.BatchNorm1d(out_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "    return nn.Sequential(*layers[:-1])  # Exclude final ReLU non-linearity\n",
    "\n",
    "# Splits a tensor in half along the final dimension\n",
    "def split_in_half(t):\n",
    "    return t.reshape(t.shape[:-1] + (2, -1)).unbind(-2)\n",
    "\n",
    "# Helper for broadcasting inputs to neural net\n",
    "def broadcast_inputs(input_args):\n",
    "    shape = broadcast_shape(*[s.shape[:-1] for s in input_args]) + (-1,)\n",
    "    input_args = [s.expand(shape) for s in input_args]\n",
    "    return input_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder and Decoder networks\n",
    "todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scANVI model\n",
    "todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting / Visualizing Results\n",
    "todo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pytorch_pyro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
