{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projects: Predicting Car Fuel Efficiency and MNIST Digits\n",
    "\n",
    "These projects are from Chapter 13 of Raschka et al and cover some basic data processing steps and make use of the concepts discussed in pyotrch-mechanics.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1: Predicting Car Fuel Efficiency\n",
    "\n",
    "Here we want to predict the fuel efficiency of a car given features such as year, cylinders, horsepower, weight, etc. This is the famous \"Auto MPG\" dataset.\n",
    "\n",
    "Some of the useful features of this project:\n",
    "\n",
    "* It contains both continuous, discrete, and categorical variables, so we learn how to deal with those\n",
    "* Shows how to \"bucket\" discrete data into a few broader buckets\n",
    "* One hot encoding for categorical features\n",
    "* It is regression rather than classification, while we've focused on the latter so far\n",
    "* Example of loading data from a URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
       "393  27.0          4         140.0        86.0  2790.0          15.6   \n",
       "394  44.0          4          97.0        52.0  2130.0          24.6   \n",
       "395  32.0          4         135.0        84.0  2295.0          11.6   \n",
       "396  28.0          4         120.0        79.0  2625.0          18.6   \n",
       "397  31.0          4         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     Model Year  Origin  \n",
       "393          82       1  \n",
       "394          82       2  \n",
       "395          82       1  \n",
       "396          82       1  \n",
       "397          82       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start by loading data from UCI machine learning repository using pandas\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "df = pd.read_csv(url, names=column_names,\n",
    "                 na_values = \"?\", comment='\\t',\n",
    "                 sep=\" \", skipinitialspace=True)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MPG</th>\n",
       "      <td>318.0</td>\n",
       "      <td>23.583962</td>\n",
       "      <td>7.890750</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.50</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.80</td>\n",
       "      <td>46.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cylinders</th>\n",
       "      <td>318.0</td>\n",
       "      <td>5.418239</td>\n",
       "      <td>1.682508</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Displacement</th>\n",
       "      <td>318.0</td>\n",
       "      <td>191.128931</td>\n",
       "      <td>102.212399</td>\n",
       "      <td>70.0</td>\n",
       "      <td>101.75</td>\n",
       "      <td>146.0</td>\n",
       "      <td>258.00</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horsepower</th>\n",
       "      <td>312.0</td>\n",
       "      <td>103.317308</td>\n",
       "      <td>37.839804</td>\n",
       "      <td>46.0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>92.0</td>\n",
       "      <td>122.75</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>318.0</td>\n",
       "      <td>2952.047170</td>\n",
       "      <td>836.500568</td>\n",
       "      <td>1613.0</td>\n",
       "      <td>2220.75</td>\n",
       "      <td>2801.0</td>\n",
       "      <td>3533.75</td>\n",
       "      <td>5140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acceleration</th>\n",
       "      <td>318.0</td>\n",
       "      <td>15.717610</td>\n",
       "      <td>2.751966</td>\n",
       "      <td>8.5</td>\n",
       "      <td>14.00</td>\n",
       "      <td>15.5</td>\n",
       "      <td>17.40</td>\n",
       "      <td>24.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Year</th>\n",
       "      <td>318.0</td>\n",
       "      <td>75.921384</td>\n",
       "      <td>3.683467</td>\n",
       "      <td>70.0</td>\n",
       "      <td>73.00</td>\n",
       "      <td>76.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Origin</th>\n",
       "      <td>318.0</td>\n",
       "      <td>1.588050</td>\n",
       "      <td>0.808150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count         mean         std     min      25%     50%  \\\n",
       "MPG           318.0    23.583962    7.890750     9.0    17.50    23.0   \n",
       "Cylinders     318.0     5.418239    1.682508     3.0     4.00     4.0   \n",
       "Displacement  318.0   191.128931  102.212399    70.0   101.75   146.0   \n",
       "Horsepower    312.0   103.317308   37.839804    46.0    75.00    92.0   \n",
       "Weight        318.0  2952.047170  836.500568  1613.0  2220.75  2801.0   \n",
       "Acceleration  318.0    15.717610    2.751966     8.5    14.00    15.5   \n",
       "Model Year    318.0    75.921384    3.683467    70.0    73.00    76.0   \n",
       "Origin        318.0     1.588050    0.808150     1.0     1.00     1.0   \n",
       "\n",
       "                  75%     max  \n",
       "MPG             29.80    46.6  \n",
       "Cylinders        6.00     8.0  \n",
       "Displacement   258.00   455.0  \n",
       "Horsepower     122.75   230.0  \n",
       "Weight        3533.75  5140.0  \n",
       "Acceleration    17.40    24.8  \n",
       "Model Year      79.00    82.0  \n",
       "Origin           2.00     3.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a training and test split of the data using sklearn\n",
    "# also look at some summary of the features using .describe() function from sklearn\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "\n",
    "\n",
    "df_train, df_test = sklearn.model_selection.train_test_split(df, train_size=0.8, random_state=1)\n",
    "train_stats = df_train.describe().transpose()  # describe quantiles of the data\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>-0.842931</td>\n",
       "      <td>-0.500222</td>\n",
       "      <td>-0.457648</td>\n",
       "      <td>-0.193720</td>\n",
       "      <td>-0.042737</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>25.1</td>\n",
       "      <td>-0.842931</td>\n",
       "      <td>-0.500222</td>\n",
       "      <td>-0.404794</td>\n",
       "      <td>-0.277402</td>\n",
       "      <td>-0.115412</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.534472</td>\n",
       "      <td>1.104280</td>\n",
       "      <td>1.233693</td>\n",
       "      <td>1.123673</td>\n",
       "      <td>-1.169204</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>26.0</td>\n",
       "      <td>-0.842931</td>\n",
       "      <td>-0.920915</td>\n",
       "      <td>-0.748347</td>\n",
       "      <td>-0.821335</td>\n",
       "      <td>0.902042</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.345770</td>\n",
       "      <td>0.399864</td>\n",
       "      <td>-0.087667</td>\n",
       "      <td>0.401617</td>\n",
       "      <td>-0.079074</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cylinders  Displacement  Horsepower    Weight  Acceleration  \\\n",
       "393  27.0  -0.842931     -0.500222   -0.457648 -0.193720     -0.042737   \n",
       "255  25.1  -0.842931     -0.500222   -0.404794 -0.277402     -0.115412   \n",
       "72   15.0   1.534472      1.104280    1.233693  1.123673     -1.169204   \n",
       "235  26.0  -0.842931     -0.920915   -0.748347 -0.821335      0.902042   \n",
       "37   18.0   0.345770      0.399864   -0.087667  0.401617     -0.079074   \n",
       "\n",
       "     Model Year  Origin  \n",
       "393          82       1  \n",
       "255          78       1  \n",
       "72           72       1  \n",
       "235          77       3  \n",
       "37           71       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize data\n",
    "from packaging import version\n",
    "\n",
    "# the list of features we will ultimately use\n",
    "numeric_column_names = ['Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration']\n",
    "\n",
    "df_train_norm, df_test_norm = df_train.copy(), df_test.copy()\n",
    "\n",
    "\n",
    "if version.parse(pd.__version__) >= version.parse(\"2.0.0\"):\n",
    "\n",
    "    for col_name in numeric_column_names:\n",
    "        mean = train_stats.loc[col_name, 'mean']\n",
    "        std = train_stats.loc[col_name, 'std']\n",
    "        df_train_norm[col_name] = (df_train_norm[col_name] - mean) / std\n",
    "        df_test_norm[col_name] = (df_test_norm[col_name] - mean) / std\n",
    "\n",
    "else:\n",
    "\n",
    "    for col_name in numeric_column_names:\n",
    "        mean = train_stats.loc[col_name, 'mean']\n",
    "        std  = train_stats.loc[col_name, 'std']\n",
    "        df_train_norm.loc[:, col_name] = (df_train_norm.loc[:, col_name] - mean) / std\n",
    "        df_test_norm.loc[:, col_name] = (df_test_norm.loc[:, col_name] - mean) / std\n",
    "        \n",
    "df_train_norm.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of a nice feature of pytorch -- it lets you group a discrete variable with many values into a few broader \"buckets\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"bucketize\" the discrete variable \"model year\" into pre-1973, 1973-76, 1976-79, and post-1979\n",
    "boundaries = torch.tensor([73, 76, 79])  # define boundaries of our buckets\n",
    "v = torch.tensor(df_train_norm['Model Year'].values)\n",
    "df_train_norm['Model Year Bucketed'] = torch.bucketize(v, boundaries, right=True)  # right=True makes right end of bucket exclusive/closed\n",
    "v = torch.tensor(df_test_norm['Model Year'].values)\n",
    "df_test_norm['Model Year Bucketed'] = torch.bucketize(v, boundaries, right=True)\n",
    "\n",
    "numeric_column_names.append('Model Year Bucketed')  # add this to the list of features to use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will show how to one-hot encode a categorical feature. If the feature has many categories which may share some similarity, it is preferable to instead use embeddings, both in order to have a more compressed representation that is computationally tractable to work with and to capture similarity between categories. But here we have only a few categories so one-hot is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode country of origin\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "total_origin = len(set(df_train_norm['Origin']))\n",
    "\n",
    "# here i think the modulo is to change the origin from 1/2/3 to 0/1/2\n",
    "origin_encoded = one_hot(torch.from_numpy(df_train_norm['Origin'].values) % total_origin)\n",
    "x_train_numeric = torch.tensor(df_train_norm[numeric_column_names].values)  # extract only the columns we want as features\n",
    "x_train = torch.cat([x_train_numeric, origin_encoded], 1).float()  # column-wise concatenate our one-hot encoded origin feature\n",
    "\n",
    "# repeat for test data\n",
    "origin_encoded = one_hot(torch.from_numpy(df_test_norm['Origin'].values) % total_origin)\n",
    "x_test_numeric = torch.tensor(df_test_norm[numeric_column_names].values)\n",
    "x_test = torch.cat([x_test_numeric, origin_encoded], 1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use MPG as our target variable. it is continuous so this is a regression problem.\n",
    "y_train = torch.tensor(df_train_norm['MPG'].values).float()\n",
    "y_test = torch.tensor(df_test_norm['MPG'].values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i had to add this code to deal with a a few NAs\n",
    "idx = np.array(np.isnan(x_train).any(axis=1))\n",
    "x_train = x_train[idx==0][:]\n",
    "y_train = y_train[idx==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a TensorDataset and DataLoader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "batch_size = 8\n",
    "torch.manual_seed(1)\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=9, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify a sequential neural network model\n",
    "# note this is slightly different than how we did it before:\n",
    "#    we have a list of number of hidden units per layer, and\n",
    "#    give each layer a ReLU activation. this can specify \n",
    "#    sequential networks quickly if all layers and activations\n",
    "#    are the same.\n",
    "\n",
    "hidden_units = [8, 4]\n",
    "input_size = x_train.shape[1]  # input size is equal to the number of features in each example\n",
    "\n",
    "all_layers = []\n",
    "for hidden_unit in hidden_units:\n",
    "    layer = nn.Linear(input_size, hidden_unit)\n",
    "    all_layers.append(layer)\n",
    "    all_layers.append(nn.ReLU())\n",
    "    input_size = hidden_unit  # reset input_size for the next layer\n",
    "\n",
    "all_layers.append(nn.Linear(hidden_units[-1], 1))  # output layer to single MPG value prediction\n",
    "model = nn.Sequential(*all_layers)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  Loss 543.6362\n",
      "Epoch 20  Loss 9.6601\n",
      "Epoch 40  Loss 9.4157\n",
      "Epoch 60  Loss 8.5744\n",
      "Epoch 80  Loss 8.4528\n",
      "Epoch 100  Loss 7.8052\n",
      "Epoch 120  Loss 8.1525\n",
      "Epoch 140  Loss 7.6223\n",
      "Epoch 160  Loss 7.2230\n",
      "Epoch 180  Loss 7.1409\n"
     ]
    }
   ],
   "source": [
    "# now we follow a typical training procedure\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "num_epochs = 200\n",
    "log_epochs = 20 \n",
    "for epoch in range(num_epochs):\n",
    "    loss_hist_train = 0\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        pred = model(x_batch)[:, 0]\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss_hist_train += loss.item()\n",
    "    if epoch % log_epochs==0:\n",
    "        print(f'Epoch {epoch}  Loss {loss_hist_train/len(train_dl):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 5.5979\n",
      "Test MAE: 1.7947\n"
     ]
    }
   ],
   "source": [
    "# now we can make predictions on the test data and compute loss functions\n",
    "with torch.no_grad():  # used to avoid training weights further; just predict\n",
    "    pred = model(x_test.float())[:, 0]\n",
    "    loss = loss_fn(pred, y_test)\n",
    "    print(f'Test MSE: {loss.item():.4f}')\n",
    "    print(f'Test MAE: {nn.L1Loss()(pred, y_test).item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 2: Predicting MNIST Digits\n",
    "\n",
    "This is similar to what has been done in previous chapters, but here we will use a Sequential network. We will also see the \"Flatten\" function to convert a tensor to 1D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision \n",
    "from torchvision import transforms \n",
    "\n",
    "\n",
    "image_path = '../datasets/'\n",
    "\n",
    "# Compose lets us define trasnformations of the data. Here we will just do ToTensor,\n",
    "#   which converts the array to a PyTorch tensor and normalized 0-255 pixels to 0-1.\n",
    "# In the next chapter on CNNs we will see other transforms.\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "mnist_train_dataset = torchvision.datasets.MNIST(root=image_path, \n",
    "                                           train=True, \n",
    "                                           transform=transform, \n",
    "                                           download=False)  # not downloading since we did that in ch12\n",
    "mnist_test_dataset = torchvision.datasets.MNIST(root=image_path, \n",
    "                                           train=False, \n",
    "                                           transform=transform, \n",
    "                                           download=False)\n",
    " \n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "train_dl = DataLoader(mnist_train_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again, build a sequential network\n",
    "hidden_units = [32, 16]\n",
    "image_size = mnist_train_dataset[0][0].shape\n",
    "input_size = image_size[0] * image_size[1] * image_size[2]\n",
    "\n",
    "all_layers = [nn.Flatten()]  # here we use Flatten to flatten these images into 1D vectors for network input \n",
    "for hidden_unit in hidden_units:\n",
    "    layer = nn.Linear(input_size, hidden_unit)\n",
    "    all_layers.append(layer)\n",
    "    all_layers.append(nn.ReLU())\n",
    "    input_size = hidden_unit\n",
    "\n",
    "all_layers.append(nn.Linear(hidden_units[-1], 10))\n",
    "model = nn.Sequential(*all_layers)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  Accuracy 0.8531\n",
      "Epoch 1  Accuracy 0.9287\n",
      "Epoch 2  Accuracy 0.9413\n",
      "Epoch 3  Accuracy 0.9506\n",
      "Epoch 4  Accuracy 0.9558\n",
      "Epoch 5  Accuracy 0.9592\n",
      "Epoch 6  Accuracy 0.9627\n",
      "Epoch 7  Accuracy 0.9650\n",
      "Epoch 8  Accuracy 0.9674\n",
      "Epoch 9  Accuracy 0.9690\n",
      "Epoch 10  Accuracy 0.9710\n",
      "Epoch 11  Accuracy 0.9729\n",
      "Epoch 12  Accuracy 0.9739\n",
      "Epoch 13  Accuracy 0.9750\n",
      "Epoch 14  Accuracy 0.9764\n",
      "Epoch 15  Accuracy 0.9777\n",
      "Epoch 16  Accuracy 0.9779\n",
      "Epoch 17  Accuracy 0.9798\n",
      "Epoch 18  Accuracy 0.9806\n",
      "Epoch 19  Accuracy 0.9813\n"
     ]
    }
   ],
   "source": [
    "# standard training loop\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    accuracy_hist_train = 0\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        pred = model(x_batch)\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n",
    "        accuracy_hist_train += is_correct.sum()\n",
    "    accuracy_hist_train /= len(train_dl.dataset)\n",
    "    print(f'Epoch {epoch}  Accuracy {accuracy_hist_train:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9647\n"
     ]
    }
   ],
   "source": [
    "# make model predictions and compute accuracy\n",
    "pred = model(mnist_test_dataset.data / 255.)  # divide by 255 to get 0-1 scale\n",
    "# prediction will be digit class with highest probability (argmax); compare with truth\n",
    "is_correct = (torch.argmax(pred, dim=1) == mnist_test_dataset.targets).float()\n",
    "print(f'Test accuracy: {is_correct.mean():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyro_pytorch_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
